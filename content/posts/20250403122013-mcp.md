+++
title = "mcp"
author = ["Cyven Chaney"]
draft = false
+++

-   belong: TODO
-   issue: TODO
-   relation: TODO


## resource {#resource}


### youtube {#youtube}


#### <https://www.youtube.com/watch?v=_d0duu3dED4> {#https-www-dot-youtube-dot-com-watch-v-d0duu3ded4}

today we're diving into the model
context protocol or MCP One of the most
significant advancements in LLM
integration released by Anthropic in
late
2024 So what exactly is MCP at its core
the model context protocol is an open
standard that enables seamless
integration between AI models like
claude and external data sources or
tools is addressing a fundamental
limitation that has held back AI
assistance from reaching their potential
Before MCP connecting models to each new
data source require custom
implementations which can get expensive
MCB solves this by providing a universal
open standard for connecting AI systems
with data sources replacing fragmented
integrations with a single protocol This
means we can give AI systems access to
databases file systems APIs and other
tools in a standardized way Let's break
down the architecture MCP follows a
client server models with three key
components Hosts clients and servers
Host are LLM applications like cloud
desktop that provide the environment for
connections Clients are components
within the host that establish and
maintain onetoone connections with
external servers Servers are separate
processes that provide context tools and
prompts to these clients exposing
specific capabilities through the
standardized protocol Let's dive deeper
into the five core primitives that power
MCP These primitives are the building
blocks that enable standardized
communication between AI models and
external systems
Servers support three primitives First
prompts These are instructions or
templates that can be injected into the
LLM context They guide how the model
should approach certain tasks or data
Second resources structured data objects
that can be included in the LLM's
context window They allow the model to
reference external information Third
tools Executable functions that the LLM
can call to retrieve information or
perform actions outside its context like
quering a database or modifying a file
On the client side there are two
primitives that are equally important
First the root primitive Think of it as
creating a secure channel for file
access It allows the AI application to
safely work with files on your local
system by opening documents reading code
or analyzing data files without giving
unrestricted access to your entire file
system Second the sampling primitive
This enables a server to request the
LLM's help when needed For example if an
MCP server is analyzing your database
schema it needs to generate a relevant
query you can ask the LLM to help
formulate that query through the
sampling primitive This create a two-way
interaction where both the AI and the
external tools can initiate requests to
each other making the whole system more
flexible and
powerful Now the real power of MCP
becomes clear when we consider the N byN
problem it solves Previously integrating
n different LLMs with m different tools
require m by m different integrations
with mcp tool builders who implement one
protocol and llm vendors like anthropic
implement the same protocol dramatically
simplifying the integration landscape
Let's look at a practical example using
cloud When we need cloud to analyze data
from our postgress database we don't
need to build a custom integration
Instead we can use an MCP server for
Postgress that exposes database
connections through the protocol's
primitives Claude through an MCP client
can then query the database where MCP
server process the results and
incorporate the insight into its
responses all while maintaining security
and context The ecosystem is growing
rapidly Developers have already created
many integrations using MCP for systems
like Google Drive Slack GitHub Git and
Postgress There are SDKs availables in
multiple languages including Typescript
and Python making it easier to implement
in various environments Looking ahead
MCP is positioned to become a
foundational technology in the AI
landscape particularly for building
sophisticated AI applications that
interact with diverse data sources and
tools The open source nature and growing
ecosystem make it accessible to
developers of all sizes If you like our
videos you might like our system design
newsletter as well It covers topics and
trends in large scale system design
trusted by 1 million readers Subscribe
at blog.byo.com
